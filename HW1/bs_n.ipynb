{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(object):\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8):\n",
    "        \"\"\"\n",
    "        Use recommended parameters from paper of Adam: \n",
    "            -- https://arxiv.org/abs/1412.6980\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.eps = epsilon\n",
    "        self.iter = 1\n",
    "    def update(self, params, grads):\n",
    "        f_param = params.ravel()\n",
    "        f_grad  = grads.ravel()\n",
    "        if not hasattr(self, 'ms'):\n",
    "            self.ms = np.zeros_like(f_param)\n",
    "            self.vs = np.zeros_like(f_param)\n",
    "        for i, (x, dx, m, v) in enumerate(zip(f_param, f_grad, self.ms, self.vs)):    \n",
    "            # Evaluate:\n",
    "            m = self.beta_1*m + (1-self.beta_1)*dx # m_t = b1*m_t-1 + (1-b1)*g\n",
    "            mt = m / (1-self.beta_1**self.iter) # m_t_h = m_t / (1-b1^t)\n",
    "            v = self.beta_2*v + (1-self.beta_2)*(dx**2) # v_t = b2*v_t-1 + (1-b2)*g^2\n",
    "            vt = v / (1-self.beta_2**self.iter) # v_t_h = v_t / (1-b2^t)\n",
    "            \n",
    "            # Update:\n",
    "            f_param[i] -= self.lr * mt / (np.sqrt(vt) + self.eps) # theta = -lr * m_t_h / (sqrt(v_t_h) + eps)\n",
    "            self.ms[i] = m # write m_t to memory (update from m_t-1 to m_t)\n",
    "            self.vs[i] = v # write v_t to memory (update from v_t-1 to v_t)\n",
    "        self.iter += 1\n",
    "\n",
    "def train(x, g_f, batch_size=1, iterations=2000, optimizer=Adam(), approximate_gradient=False, f=None, x_eps=1e-7):\n",
    "    x = x.copy()\n",
    "    for _ in range(iterations):\n",
    "        if approximate_gradient:\n",
    "            grad = np.repeat(( (f(x+x_eps) - f(x)) / x_eps ).mean(axis=0, keepdims=True), x.shape[0], axis=0)\n",
    "        else:\n",
    "            grad= np.repeat(g_f(x).mean(axis=0, keepdims=True), x.shape[0], axis=0)\n",
    "        optimizer.update(x, grad)\n",
    "    return x.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic definition of fx funciton\n",
    "# fx = lambda x: x**4 - 3*(x**2) + 2\n",
    "# g_fx = lambda x: 4*x**3 - 6*x\n",
    "def fx(x):\n",
    "    return x**4 - 3*(x**2) + 2\n",
    "\n",
    "def g_fx(x):\n",
    "    return 4*x**3 - 6*x\n",
    "\n",
    "# Basic definition of rosenbrock function\n",
    "# rosenbrock = lambda x1, x2: 100*(x2-x1)**2 + (1-x1)**2\n",
    "# g_rosenbrock = lambda x1, x2: (202*x1 - 200*x2 - 2, -200*(x1-x2)) # partial_x1, partial_x2\n",
    "def rosenbrock(x):\n",
    "    return 100*(x[...,1]-x[...,0])**2 + (1-x[...,0])**2 # (batch_size)\n",
    "\n",
    "def g_rosenbrock(x):\n",
    "    ret = np.zeros_like(x)\n",
    "    ret[...,0] = 202*x[...,0] - 200*x[...,1] - 2\n",
    "    ret[...,1] = -200*(x[...,0]-x[...,1])\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fx_x:', array([[-0.78910299]]))\n"
     ]
    }
   ],
   "source": [
    "fx_x = np.random.randn(BATCH_SIZE,1)\n",
    "print('fx_x:', fx_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('rosenbrock_x:', array([[ 0.11219411, -0.38462552]]))\n"
     ]
    }
   ],
   "source": [
    "rosenbrock_x = np.random.randn(BATCH_SIZE,2)\n",
    "print('rosenbrock_x:', rosenbrock_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_fx = train(fx_x, g_fx, 20000, approximate_gradient=True, f=fx)\n",
    "# min_rosenbrock = train(rosenbrock_x, g_rosenbrock, 200000, approximate_gradient=True, f=rosenbrock)\n",
    "min_fx = train(fx_x, g_fx, 20000)\n",
    "min_rosenbrock = train(rosenbrock_x, g_rosenbrock, 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('min_fx:', array([-1.22474487]))\n",
      "('min_rosenbrock', array([-0.37091635, -0.38462552]))\n"
     ]
    }
   ],
   "source": [
    "print('min_fx:', min_fx)\n",
    "print('min_rosenbrock', min_rosenbrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
