{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(object):\n",
    "    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8):\n",
    "        \"\"\"\n",
    "        Use recommended parameters from paper of Adam: \n",
    "            -- https://arxiv.org/abs/1412.6980\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "        self.eps = epsilon\n",
    "        self.iter = 1\n",
    "    def update(self, params, grads):\n",
    "        f_param = params.ravel()\n",
    "        f_grad  = grads.ravel()\n",
    "        if not hasattr(self, 'ms'):\n",
    "            self.ms = np.zeros_like(f_param)\n",
    "            self.vs = np.zeros_like(f_param)\n",
    "        for i, (x, dx, m, v) in enumerate(zip(f_param, f_grad, self.ms, self.vs)):    \n",
    "            # Evaluate:\n",
    "            m = self.beta_1*m + (1-self.beta_1)*dx # m_t = b1*m_t-1 + (1-b1)*g\n",
    "            mt = m / (1-self.beta_1**self.iter) # m_t_h = m_t / (1-b1^t)\n",
    "            v = self.beta_2*v + (1-self.beta_2)*(dx**2) # v_t = b2*v_t-1 + (1-b2)*g^2\n",
    "            vt = v / (1-self.beta_2**self.iter) # v_t_h = v_t / (1-b2^t)\n",
    "            \n",
    "            # Update:\n",
    "            f_param[i] -= self.lr * mt / (np.sqrt(vt) + self.eps) # theta = -lr * m_t_h / (sqrt(v_t_h) + eps)\n",
    "            self.ms[i] = m # write m_t to memory (update from m_t-1 to m_t)\n",
    "            self.vs[i] = v # write v_t to memory (update from v_t-1 to v_t)\n",
    "        self.iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adagrad(object):\n",
    "    def __init__(self, lr=0.001, decay_rate=0.9, epsilon=1e-8):\n",
    "        \"\"\"\n",
    "        Ref from CS231n:\n",
    "        http://cs231n.github.io/neural-networks-3\n",
    "        cache = decay_rate * cache + (1 - decay_rate) * dx**2\n",
    "        x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.decay = decay_rate\n",
    "        self.eps = epsilon\n",
    "    def update(self, params, grads):\n",
    "        f_param = params.ravel()\n",
    "        f_grad  = grads.ravel()\n",
    "        if not hasattr(self, 'cache'):\n",
    "            self.cache = np.zeros_like(f_param)\n",
    "        for i, (x, dx, c) in enumerate(zip(f_param, f_grad, self.cache)):\n",
    "            # Evaluate:\n",
    "            c_t = self.decay * c + (1 - self.decay) * dx**2\n",
    "            \n",
    "            # Update:\n",
    "            f_param[i] -= self.lr * dx / (np.sqrt(c_t) + self.eps) \n",
    "            self.cache[i] = c_t # update cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize(x, g_f, iterations=2000, optimizer=None, approximate_gradient=False, f=None, x_eps=1e-8, return_seq=False):\n",
    "    x = x.copy()\n",
    "    if return_seq:\n",
    "        xt = [x.copy()]\n",
    "        yt = [f(x)]\n",
    "    for _ in range(iterations):\n",
    "        if approximate_gradient:\n",
    "            grad = (f(x+x_eps) - f(x)) / x_eps \n",
    "        else:\n",
    "            grad = g_f(x)\n",
    "        optimizer.update(x, grad)\n",
    "        if return_seq:\n",
    "            xt.append(x.copy())\n",
    "            yt.append(f(x))\n",
    "    if return_seq:\n",
    "        return x, xt, yt\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic definition of fx funciton\n",
    "fx_lambda = lambda x: x**4 - 3*(x**2) + 2\n",
    "# g_fx = lambda x: 4*x**3 - 6*x\n",
    "def fx(x):\n",
    "    return np.squeeze(x**4 - 3*(x**2) + 2) # scaler\n",
    "\n",
    "def g_fx(x):\n",
    "    ret = np.zeros_like(x)\n",
    "    ret[...] = 4*x**3 - 6*x\n",
    "    return ret\n",
    "\n",
    "# Basic definition of rosenbrock function\n",
    "rosenbrock_lambda = lambda x1, x2: 100*(x2-x1)**2 + (1-x1)**2\n",
    "# g_rosenbrock = lambda x1, x2: (202*x1 - 200*x2 - 2, -200*(x1-x2)) # partial_x1, partial_x2\n",
    "def rosenbrock(x):\n",
    "    return np.squeeze(100*(x[...,1]-x[...,0])**2 + (1-x[...,0])**2)  # scaler\n",
    "\n",
    "def g_rosenbrock(x):\n",
    "    ret = np.zeros_like(x)\n",
    "    ret[...,0] = 202*x[...,0] - 200*x[...,1] - 2\n",
    "    ret[...,1] = -200*(x[...,0]-x[...,1])\n",
    "    return ret\n",
    "\n",
    "basin_lambda = lambda x, y: np.sin(x**2 + y**2)\n",
    "def basin(x):\n",
    "    return np.squeeze(np.sin(x[...,0]**2 + x[...,1]**2))\n",
    "def g_basin(x):\n",
    "    ret = np.zeros_like(x)\n",
    "    ret[...,0] = 2 * x[...,0] * np.cos(x[...,0]**2 + x[...,1]**2)\n",
    "    ret[...,1] = 2 * x[...,1] * np.cos(x[...,0]**2 + x[...,1]**2)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_surface(func=rosenbrock_lambda ,xlim=[-5, 5], ylim=[-5, 5], step=0.25):\n",
    "    X = np.arange(xlim[0], xlim[1], step)\n",
    "    Y = np.arange(ylim[0], ylim[1], step)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    Z = func(X, Y)\n",
    "    return X, Y, Z\n",
    "\n",
    "def make_line(func=fx_lambda, xlim=[-5, 5], step=0.25):\n",
    "    X = np.arange(xlim[0], xlim[1], step)\n",
    "    Y = func(X)\n",
    "    return X, Y\n",
    "\n",
    "def visualize(title_name='Gradient Descent Animation (Adam)' ,filename='test.mp4', fps=30, xs=None, ys=None, f=None, xlim=[-5,5], ylim=[-5,5], step=0.3, skip=10):\n",
    "    xs = np.asarray(xs[::skip])\n",
    "    ys = np.asarray(ys[::skip])\n",
    "    \n",
    "    if xs.shape[-1]==1: # 2D animation\n",
    "        pass\n",
    "    elif xs.shape[-1]==2: # 3D animation\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        ax = p3.Axes3D(fig)\n",
    "        ax.view_init(80, 40)\n",
    "        \n",
    "        x, y, z = make_surface(f, xlim=xlim, ylim=ylim, step=step)\n",
    "        ax.plot_surface(x, y, z, rstride=1, cstride=1, edgecolor='none', alpha=.8, cmap=plt.cm.jet)\n",
    "\n",
    "        line, = ax.plot([], [], [], 'b', lw=2)\n",
    "\n",
    "        ax.set_title(title_name)\n",
    "        ax.set_xlabel('$x$')\n",
    "        ax.set_ylabel('$y$')\n",
    "        ax.set_zlabel('$z$')\n",
    "\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        \n",
    "        def init():\n",
    "            line.set_data([], [])\n",
    "            line.set_3d_properties([])\n",
    "            return line, \n",
    "        def animate(i):\n",
    "            x, y, z = xs[:i,0], xs[:i,1], ys[:i]\n",
    "            line.set_data(x, y)\n",
    "            line.set_3d_properties(z)\n",
    "            return line, \n",
    "        \n",
    "        ani = animation.FuncAnimation(fig, animate, frames=len(xs), init_func=init,\n",
    "                                   interval=200, blit=True)\n",
    "        ani.save(filename, fps=fps, extra_args=['-vcodec', 'libx264'])\n",
    "        plt.cla()   # Clear axis\n",
    "        plt.clf()   # Clear figure\n",
    "        plt.close('all')\n",
    "    else:\n",
    "        raise RuntimeError('Only accept 2D/3D plot!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fx_x:', array([-0.98682012]))\n"
     ]
    }
   ],
   "source": [
    "fx_x = np.random.randn(1)\n",
    "print('fx_x:', fx_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('rosenbrock_x:', array([-4,  4]))\n"
     ]
    }
   ],
   "source": [
    "rosenbrock_x = np.array([-4, 4])\n",
    "print('rosenbrock_x:', rosenbrock_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('basin_x:', array([ 0.9, -0.8]))\n"
     ]
    }
   ],
   "source": [
    "basin_x = np.array([0.9, -0.8])\n",
    "print('basin_x:', basin_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Adagrad', 'fx', array([-1.22524456]), array(0.02687176), 4000)\n",
      "('Adam', 'fx', array([-1.22474487]), array(0.02687176), 4000)\n",
      "('Adagrad', 'basin', array([0.00049999, 0.0005    ]), 0.9927129910375885, 4000)\n",
      "('Adam', 'basin', array([ 2.89105623e-16, -8.75941594e-22]), 0.9927129910375885, 4000)\n",
      "('Adagrad', 'rosenbrock', array([0, 0]), 6425, 6000)\n",
      "('Adam', 'rosenbrock', array([0, 0]), 6425, 6000)\n"
     ]
    }
   ],
   "source": [
    "optimizers = [Adagrad, Adam]\n",
    "funcs = [fx,basin,rosenbrock]\n",
    "funcs_lambda = [fx_lambda,basin_lambda,rosenbrock_lambda]\n",
    "grads = [g_fx,g_basin,g_rosenbrock]\n",
    "xs    = [fx_x,basin_x,rosenbrock_x]\n",
    "xlims = [[-2, 2],[-1.5, 1.5],[-4, 4]]\n",
    "ylims = [None,[-1.5, 1.5],[-4, 4]]\n",
    "iters = [4000,4000,6000]\n",
    "for func, func_lambda, x, g_func, iter_, xl, yl in zip(funcs, funcs_lambda, xs, grads, iters, xlims, ylims):\n",
    "    for opt_class in optimizers:\n",
    "        opt = opt_class()\n",
    "        final_x, xs, ys = minimize(x, g_func, iterations=iter_, optimizer=opt, f=func, return_seq=True, approximate_gradient=False)\n",
    "        title_name = '_'.join(list(map(str, [type(opt).__name__, func.__name__])))\n",
    "        visualize(title_name=title_name, filename=title_name+'.mp4', xs=xs, ys=ys, f=func_lambda, xlim=xl, ylim=yl, skip=10)\n",
    "        print(type(opt).__name__, func.__name__, final_x, func(x), iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
